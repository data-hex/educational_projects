{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02d84b3c",
   "metadata": {},
   "source": [
    "task https://stepik.org/lesson/701336/step/6?unit=701405"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aafcf4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл res_parse.csv создан\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#create file\n",
    "with open('res_parse.csv', 'w', encoding='utf-8-sig', newline='') as file:\n",
    "    writer = csv.writer(file, delimiter=';')\n",
    "    writer.writerow([\n",
    "        'Наименование', 'Артикул', 'Бренд', 'Модель', 'Тип', 'Технология экрана', 'Материал корпуса', 'Материал браслета', 'Размер', 'Сайт производителя', 'Наличие', 'Цена', 'Старая цена',  'Ссылка на карточку с товаром'])    \n",
    "\n",
    "url = 'https://parsinger.ru/html/index1_page_1.html'\n",
    "site = 'http://parsinger.ru/html/'\n",
    "\n",
    "def get_response(url):\n",
    "    response = requests.get(url=url)\n",
    "    response.encoding = 'utf-8'  \n",
    "    return response\n",
    "\n",
    "def cook_pagination(response,site):\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    pages = [f\"{site}{link['href']}\" for link in soup.find('div', class_='pagen').find_all('a')]        \n",
    "    return pages\n",
    "\n",
    "\n",
    "def flatten(list_of_lists):\n",
    "    if len(list_of_lists) == 0:\n",
    "        return list_of_lists\n",
    "    if isinstance(list_of_lists[0], list):\n",
    "        return flatten(list_of_lists[0]) + flatten(list_of_lists[1:])\n",
    "    return list_of_lists[:1] + flatten(list_of_lists[1:])\n",
    "\n",
    "def cook_products(url, response, site):\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    name = soup.find(\"p\", id='p_header' ).text\n",
    "    article = soup.find('p', class_='article').text.split()[1]\n",
    "    description = [x.text.split('\\n') for x in soup.find('ul', id ='description')]\n",
    "    description = flatten(description)\n",
    "    description = [value for value in description if value]\n",
    "    availability = soup.find(\"span\", id='in_stock').text    \n",
    "    price = soup.find('span', id='price').text\n",
    "    old_price = soup.find('span', id='old_price').text   \n",
    "    \n",
    "    flat = name, article, *[x.split(':')[1].strip() for x in description if x], availability.split()[2], price, old_price, url\n",
    "    return flat\n",
    "    \n",
    "\n",
    "\n",
    "for i in cook_pagination(get_response(url),site):    \n",
    "    soup = BeautifulSoup(get_response(i).text, 'lxml')\n",
    "    url_products = [f\"{site}{link['href']}\" for link in soup.find_all('a', class_='name_item')]\n",
    "    for url_product in url_products:\n",
    "        product_info = cook_products(url_product, get_response(url_product), site)\n",
    "        \n",
    "        with open('res_parse.csv', 'a', encoding='utf-8-sig', newline='') as file:\n",
    "            writer = csv.writer(file, delimiter=';')\n",
    "            writer.writerow(product_info)\n",
    "print('Файл res_parse.csv создан')       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40333a64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
